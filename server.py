import os
import datetime
from dotenv import load_dotenv
import uvicorn
from mcp.server.fastmcp import FastMCP
from notion_client import Client
from starlette.types import ASGIApp, Scope, Receive, Send
from pinecone import Pinecone # äº‘ç«¯æ•°æ®åº“
from sentence_transformers import SentenceTransformer # å‘é‡ç¿»è¯‘å®˜

# 1. åŠ è½½é…ç½®
load_dotenv()
notion_key = os.getenv("NOTION_API_KEY")
database_id = os.getenv("NOTION_DATABASE_ID")
pinecone_key = os.getenv("PINECONE_API_KEY")

# 2. åˆå§‹åŒ– Notion
notion = Client(auth=notion_key)

# 3. åˆå§‹åŒ– Pinecone (äº‘ç«¯è®°å¿†åº“)
print("â³ æ­£åœ¨è¿æ¥ Pinecone äº‘ç«¯å¤§è„‘...")
pc = Pinecone(api_key=pinecone_key)
# âš ï¸ ç¡®ä¿ä½ åœ¨ç½‘é¡µä¸Šåˆ›å»ºçš„ Index åå­—å« 'notion-brain'ï¼Œæˆ–è€…æ”¹æˆä½ è‡ªå·±çš„åå­—
index_name = "notion-brain" 
if index_name not in pc.list_indexes().names():
    print(f"âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨ Pinecone ç½‘é¡µä¸Šåˆ›å»ºä¸€ä¸ªå« '{index_name}' çš„ Indexï¼ç»´åº¦(Dimensions)è®¾ä¸º 384ã€‚")
    exit()
index = pc.Index(index_name)

# 4. åˆå§‹åŒ–å‘é‡æ¨¡å‹ (æœ¬åœ°ç¿»è¯‘å®˜)
# å®ƒä¼šæŠŠæ–‡å­—è½¬æ¢æˆ 384 ç»´çš„æ•°å­—åˆ—è¡¨
print("â³ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹ (ç¬¬ä¸€æ¬¡å¯èƒ½æ¯”è¾ƒæ…¢)...")
model = SentenceTransformer('all-MiniLM-L6-v2') 

mcp = FastMCP("Notion Pinecone Brain")

# --- å·¥å…· 1: å†™å…¥ (ä¿æŒä¸å˜) ---
@mcp.tool()
def write_notion_page(title: str, content: str, category: str = "æ—¥å¸¸", date: str = None):
    if not date: date = datetime.date.today().isoformat()
    print(f"âš¡ï¸ [å†™å…¥] {title}")
    try:
        notion.pages.create(
            parent={"database_id": database_id},
            properties={
                "Title": {"title": [{"text": {"content": title}}]},
                "Category": {"select": {"name": category}},
                "Date": {"date": {"start": date}}
            },
            children=[{
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": content}}]
                }
            }]
        )
        return "âœ… å†™å…¥æˆåŠŸï¼(è®°å¾—è¿è¡Œ sync_notion_index åŒæ­¥åˆ°äº‘ç«¯)"
    except Exception as e:
        return f"âŒ å†™å…¥å¤±è´¥: {e}"

# --- å·¥å…· 2: ç²¾ç¡®è¯»å– (ä¿æŒä¸å˜) ---
@mcp.tool()
def read_notion_exact(category: str = None, date: str = None):
    print(f"âš¡ï¸ [ç²¾ç¡®æŸ¥é˜…]")
    return "è¯·ä½¿ç”¨è¯­ä¹‰æœç´¢ã€‚"

# --- å·¥å…· 3: åŒæ­¥ç´¢å¼• (å‡çº§ä¸º Pinecone ç‰ˆ) ---
@mcp.tool()
def sync_notion_index():
    print("âš¡ï¸ [å¼€å§‹åŒæ­¥] æ­£åœ¨ä» Notion ä¸‹è½½å¹¶ä¸Šä¼ åˆ° Pinecone...")
    target_id_clean = database_id.replace("-", "")
    
    try:
        all_pages = notion.search(filter={"value": "page", "property": "object"})["results"]
        
        vectors_to_upload = []
        count = 0
        
        for page in all_pages:
            parent = page.get("parent", {})
            p_id = parent.get("database_id") or parent.get("data_source_id")
            
            # ID åŒ¹é…é€»è¾‘
            if p_id and p_id.replace("-", "") == target_id_clean:
                try:
                    # 1. æå–å…ƒæ•°æ®
                    props = page["properties"]
                    t_obj = props.get("Title", {}).get("title", [])
                    title = t_obj[0]["text"]["content"] if t_obj else "æ— æ ‡é¢˜"
                    c_obj = props.get("Category", {}).get("select")
                    category = c_obj["name"] if c_obj else "æœªåˆ†ç±»"
                    d_obj = props.get("Date", {}).get("date")
                    date = d_obj["start"] if d_obj else "æœªçŸ¥"
                    
                    # 2. è¯»å–æ­£æ–‡
                    page_id = page["id"]
                    blocks = notion.blocks.children.list(block_id=page_id)
                    content = ""
                    for b in blocks["results"]:
                        if "paragraph" in b and b["paragraph"]["rich_text"]:
                            for t in b["paragraph"]["rich_text"]:
                                content += t["text"]["content"]
                    
                    full_text = f"æ ‡é¢˜:{title}\nåˆ†ç±»:{category}\næ—¥æœŸ:{date}\nå†…å®¹:{content}"
                    
                    # 3. ç”Ÿæˆå‘é‡ (Embedding)
                    # è¿™é‡Œçš„ embedding æ˜¯ä¸€ä¸ª 384 ä¸ªæ•°å­—ç»„æˆçš„åˆ—è¡¨
                    embedding = model.encode(full_text).tolist()
                    
                    # 4. å‡†å¤‡ Pinecone æ•°æ®åŒ…
                    # æ ¼å¼: (ID, å‘é‡, å…ƒæ•°æ®)
                    vectors_to_upload.append((
                        page_id, 
                        embedding, 
                        {"text": full_text, "category": category, "date": date, "title": title}
                    ))
                    
                    count += 1
                    print(f"   Prepared: {title}")
                    
                except Exception as e:
                    print(f"   âš ï¸ è·³è¿‡é¡µé¢: {e}")
        
        if vectors_to_upload:
            # æ‰¹é‡ä¸Šä¼ åˆ° Pinecone
            print(f"ğŸš€ æ­£åœ¨ä¸Šä¼  {len(vectors_to_upload)} æ¡è®°å¿†åˆ°äº‘ç«¯...")
            index.upsert(vectors=vectors_to_upload)
            msg = f"âœ… åŒæ­¥å®Œæˆï¼{count} æ¡è®°å¿†å·²æ°¸ä¹…å­˜å…¥ Pineconeã€‚"
        else:
            msg = "âš ï¸ æ²¡æ‰¾åˆ°éœ€è¦åŒæ­¥çš„å†…å®¹ã€‚"
            
        print(msg)
        return msg
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"âŒ åŒæ­¥å¤±è´¥: {e}"

# --- å·¥å…· 4: è¯­ä¹‰æœç´¢ (å‡çº§ä¸º Pinecone ç‰ˆ) ---
@mcp.tool()
def search_memory_semantic(query: str, n_results: int = 3):
    print(f"âš¡ï¸ [äº‘ç«¯æ€è€ƒ]: {query}")
    try:
        # 1. æŠŠé—®é¢˜ä¹Ÿå˜æˆå‘é‡
        query_embedding = model.encode(query).tolist()
        
        # 2. å» Pinecone é‡Œæœæœ€ç›¸ä¼¼çš„å‘é‡
        result = index.query(
            vector=query_embedding,
            top_k=n_results,
            include_metadata=True # è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œè¦æŠŠåŸæ–‡æ‹¿å›æ¥
        )
        
        matches = result.get("matches", [])
        if not matches:
            return "ğŸ§  äº‘ç«¯å¤§è„‘é‡Œæ²¡æ‰¾åˆ°ç›¸å…³è®°å¿†ã€‚"
            
        answer = "Found:\n"
        for match in matches:
            score = match["score"]
            text = match["metadata"]["text"]
            date = match["metadata"]["date"]
            # è¿‡æ»¤æ‰ç›¸å…³æ€§å¤ªä½çš„ (æ¯”å¦‚åˆ†æ•°å°äº 0.3)
            if score > 0.3:
                answer += f"---\n[ç›¸å…³åº¦ {score:.2f} | {date}]\n{text}\n"
        
        return answer
    except Exception as e:
        return f"âŒ Error: {e}"

# --- ä¸­é—´ä»¶ ---
class HostFixMiddleware:
    def __init__(self, app: ASGIApp): self.app = app
    async def __call__(self, scope: Scope, receive: Receive, send: Send):
        if scope["type"] == "http":
            headers = dict(scope.get("headers", []))
            headers[b"host"] = b"localhost:8000"
            scope["headers"] = list(headers.items())
        await self.app(scope, receive, send)

if __name__ == "__main__":
    print("ğŸš€ ã€Pinecone æ°¸ç”Ÿç‰ˆã€‘æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    # è‡ªåŠ¨é€‚é…äº‘ç«¯ç«¯å£
    port = int(os.environ.get("PORT", 8000))
    raw_app = mcp.sse_app()
    final_app = HostFixMiddleware(raw_app)
    uvicorn.run(final_app, host="0.0.0.0", port=port, http="h11")